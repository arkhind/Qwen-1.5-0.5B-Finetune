{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb3d449-a20d-47b6-ba79-1f260817f21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5b208e-3d97-4068-b1fb-7b22e49b2e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3939ae21-574b-4608-92ce-287d198f634a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0107e9-2474-45da-9cc7-83a71d31de09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (2.4.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.43.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.33.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.24.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->peft) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.7.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc10d2c-d516-4a54-b8cb-85281911664c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112f11b7-e1e0-47d8-a7f3-fc64a7183621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user_pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc0b7ee-e633-46c1-9fff-5dc028ce9850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b688a8de97954a2eb6c38848eccc7a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e7b9eab1344268dbd04ed0b27cd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"suriyagunasekar/stackoverflow-python-with-meta-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d294f4a2-c23f-4d07-b794-1803c5608c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df\n",
    "ds_copy = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69abdbb2-7d1a-4fd7-93e8-d14a36ff92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b97d2bb-d2c6-4a4e-a5e2-89dee565afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['content']\n",
    "del data['title']\n",
    "del data['answers_scores']\n",
    "del data['non_answers']\n",
    "del data['non_answers_scores']\n",
    "del data['tags']\n",
    "del data['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5557161-af8c-414e-9dfd-5ed26c024855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've got a menu in Python. That part was easy....</td>\n",
       "      <td>[On Windows:\\nimport msvcrt\\nanswer=msvcrt.get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have created a PHP-script to update a web se...</td>\n",
       "      <td>[Do you need to open the locfile in binary usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have a Prolite LED sign that I like to set u...</td>\n",
       "      <td>[/dev/cu.xxxxx is the \"callout\" device, it's w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have a cross-platform (Python) application w...</td>\n",
       "      <td>[ImageMagick delegates the PDF-&gt;bitmap convers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basically, I've written an API to www.thetvdb....</td>\n",
       "      <td>[OK, what you need is classobj from new module...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  I've got a menu in Python. That part was easy....   \n",
       "1  I have created a PHP-script to update a web se...   \n",
       "2  I have a Prolite LED sign that I like to set u...   \n",
       "3  I have a cross-platform (Python) application w...   \n",
       "4  Basically, I've written an API to www.thetvdb....   \n",
       "\n",
       "                                             answers  \n",
       "0  [On Windows:\\nimport msvcrt\\nanswer=msvcrt.get...  \n",
       "1  [Do you need to open the locfile in binary usi...  \n",
       "2  [/dev/cu.xxxxx is the \"callout\" device, it's w...  \n",
       "3  [ImageMagick delegates the PDF->bitmap convers...  \n",
       "4  [OK, what you need is classobj from new module...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a768975d-1d50-4eb4-ba8a-844546b5a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1745972/1745972 [00:01<00:00, 1352213.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_first_ans(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "data['answers'] = data['answers'].progress_apply(extract_first_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0992c026-273d-41e6-ba80-7876d8c26d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc74c15e-9c4d-4834-b150-1af9a39a85bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen1.5-0.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baf0a861-b29d-400d-a086-2d376237913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b65d4f5-d44c-4f7b-908f-899ae6ee0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258172b7-75be-44ab-9b7c-e2040ba06281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 786,432 || all params: 464,774,144 || trainable%: 0.1692\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2380659-8938-47c5-9c3f-2ef769ce5c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c90716a-0762-44cc-86af-5b19689852a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "597330",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 597330",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m      4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m      5\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2236\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2233\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2236\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   2239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 597330"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1eadde77-d727-46f8-b7cd-161a59bcbcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a panda data frame that looks like this:\n",
      "ID   Key\n",
      "101  A\n",
      "102  A\n",
      "205  A\n",
      "101  B\n",
      "105  A\n",
      "605  A\n",
      "200  A\n",
      "102  B\n",
      "\n",
      "I would like to make a new table that counts the number of occurrences of \"A\" and \"B\" in the Key column and make them as new two headers. The table would then look like this:\n",
      "ID  A  B \n",
      "101 1  1\n",
      "102 1  1\n",
      "205 1  0\n",
      "105 1  0\n",
      "605 1  0\n",
      "200 1  0\n",
      "\n",
      "I have treid groubing by 'ID' and  'Key' and get the sizes as here:\n",
      "df.groupby(['ID', 'Key']).size().transform('A', 'B')\n",
      "\n",
      "But it says the series doesn't have the attribute 'transform', and actually, I am not even sure if I can have two arguments passed to 'transform'\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!! You are close, need unstack:\n",
      "df = df.groupby(['ID', 'Key']).size().unstack(fill_value=0)\n",
      "print (df)\n",
      "Key  A  B\n",
      "ID       \n",
      "101  1  1\n",
      "102  1  1\n",
      "105  1  0\n",
      "200  1  0\n",
      "205  1  0\n",
      "605  1  0\n",
      "\n",
      "Or crosstab:\n",
      "df = pd.crosstab(df['ID'], df['Key'])\n",
      "print (df)\n",
      "Key  A  B\n",
      "ID       \n",
      "101  1  1\n",
      "102  1  1\n",
      "105  1  0\n",
      "200  1  0\n",
      "205  1  0\n",
      "605  1  0\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "How to calculate (e.g.) sum on multi index DataFrame level=1 for every column and store results in a new DataFrame like getting from this_to_that.\n",
      "data\n",
      "T = ['t1','t2']\n",
      "S = ['S1','S2']\n",
      "K = ['earnings','costs']\n",
      "\n",
      "multi_index = pd.MultiIndex.from_product([T,S])\n",
      "input_df = pd.DataFrame(index = multi_index, columns = K)\n",
      "input_df['earnings'] = (150.0,25.0,80.0,40.0)\n",
      "input_df['costs'] = (150.0,12.5,36.36,22.72)\n",
      "\n",
      "my overlaborate way\n",
      "dc = dict()\n",
      "for t in T:\n",
      "    dc[t] = input_df.xs(t, level = 0, axis = 0).apply(sum, axis = 0)\n",
      "\n",
      "dc_to_df = pd.concat(dc)\n",
      "dc_to_df = pd.DataFrame(dc_to_df)\n",
      "dc_to_df = dc_to_df.unstack(level=1)\n",
      "dc_to_df.columns = dc_to_df.columns.droplevel(0)\n",
      "desired_df = dc_to_df\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!  Is this what you're looking for?\n",
      "input_df\n",
      "       earnings   costs\n",
      "t1 S1     150.0  150.00\n",
      "   S2      25.0   12.50\n",
      "t2 S1      80.0   36.36\n",
      "   S2      40.0   22.72\n",
      "\n",
      "input_df.groupby(level=0).sum()\n",
      "    earnings   costs\n",
      "t1     175.0  162.50\n",
      "t2     120.0   59.08\n",
      "\n",
      "You can assign the above output to a new dataframe.\n",
      "EDIT: After looking at your output you're actually grouping on level=0.\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "I am currently developing locally on Windows but then need to upload my files to a Linux server.  However, I'm running into a problem where I need to include a shebang at the top of each of my files to tell Apache which python application to run, and that will naturally be different on Windows and Linux, such that I would need to change all of my files as part of uploading them to Linux.  Is there a way to either remove the need for the shebang or provide a shebang that works under both Windows and Linux?\n",
      "my httpd.conf\n",
      "<IfModule wsgi_module>\n",
      "    LoadFile \"C:/Python/Python36-32/python36.dll\"\n",
      "    LoadModule wsgi_module \"C:/Python/Python36-32/lib/site-packages/mod_wsgi/server/mod_wsgi.cp36-win32.pyd\"\n",
      "    WSGIPythonHome \"C:/Python/Python36-32\"\n",
      "</IfModule>\n",
      "\n",
      "<VirtualHost 127.0.0.1:80>\n",
      "    DocumentRoot \"C:/Python/Web\"\n",
      "    <Directory \"C:/Python/Web\">\n",
      "        Allow from all\n",
      "        Require all granted\n",
      "        Options Indexes Includes ExecCGI FollowSymLinks\n",
      "        AllowOverride All\n",
      "        Order deny,allow\n",
      "        DirectoryIndex index.py\n",
      "    </Directory>\n",
      "    AddHandler cgi-script .cgi .pl .py\n",
      "</VirtualHost>\n",
      "\n",
      "if my index.py includes the shebang, e.g. it looks like:\n",
      "#!C:\\Python\\Python36-32\\python.exe\n",
      "print(\"Content-Type: text\\html\\n\")\n",
      "print(\"Heelolo ->>>>>>>>\")\n",
      "\n",
      "--> On Windows, I get the expected result: \n",
      "Heelolo ->>>>>>>>\n",
      "\n",
      "If I don't include the shebang, e.g.:\n",
      "print(\"Content-Type: text\\html\\n\")\n",
      "print(\"Heelolo ->>>>>>>>\")\n",
      "\n",
      "I get the following message in my apache error.log\n",
      "[Fri May 26 14:05:31.326900 2017] [win32:error] [pid 4700:tid 1972] [client 127.0.0.1:50743] AH02102: C:/Web/Hello/index.py is not executable; ensure interpreted scripts have \"#!\" or \"'!\" first line\n",
      "\n",
      "Any ideas how I can make this work cross-platformly?\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!  Although you have tried to load mod_wsgi, you got it wrong and haven't told Apache to host any WSGI applications anyway. You also haven't converted your Python web application to be a WSGI application. See:\n",
      "\n",
      "http://modwsgi.readthedocs.io/en/develop/user-guides/quick-configuration-guide.html\n",
      "\n",
      "and also go learn about a simple Python web framework like Flask rather than try and do things from scratch.\n",
      "Before trying to that though, also remove the conditional for wsgi_module. That is, instead of:\n",
      "<IfModule wsgi_module>\n",
      "    LoadFile \"C:/Python/Python36-32/python36.dll\"\n",
      "    LoadModule wsgi_module \"C:/Python/Python36-32/lib/site-packages/mod_wsgi/server/mod_wsgi.cp36-win32.pyd\"\n",
      "    WSGIPythonHome \"C:/Python/Python36-32\"\n",
      "</IfModule>\n",
      "\n",
      "you should have just:\n",
      "LoadFile \"C:/Python/Python36-32/python36.dll\"\n",
      "LoadModule wsgi_module \"C:/Python/Python36-32/lib/site-packages/mod_wsgi/server/mod_wsgi.cp36-win32.pyd\"\n",
      "WSGIPythonHome \"C:/Python/Python36-32\"\n",
      "\n",
      "The conditional meant those directives would only be applied if the module had already been loaded. Problem is the module was loaded within that check, so obviously it wasn't going to be loaded.\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "I am using bottle and peewee as the framework in back end, sqlite3 as the DB. And the summernote is the text editor at the front. Succeed in saving the code into DB, but failed to display the text when retrieving from the DB.\n",
      "DB data:\n",
      "The Draft column is the html\n",
      "Source code:\n",
      "Front:\n",
      "$('#summernote').summernote(\"code\", \"{{content}}\");\n",
      "\n",
      "Backend: \n",
      "template('apps_post_editer', appName='Post New', pid=newPost.id, title=('' if newPost.title is None else str(newPost.title)), content=('' if newPost.draft is None else unicode(str(newPost.draft), \"utf-8\")))\n",
      "\n",
      "I thought it was the coding problem at the beginning, so i use unicode to turn the value in utf-8, but does not work. And also failed only str(newPost.draft)\n",
      "The result:\n",
      "You can see that the html code is not converted\n",
      "Question:\n",
      "Why it happens like that? Is there any solution?\n",
      "Thanks very much.\n",
      "Update: sorry it is my first question, don't know why the picture don't display...Please click the link to get more details...\n",
      "OK...need 10 reputation\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!  When you want to render HTML that comes from the database with bottle, you have to tell the rendering engine that the content is safe to render in order to avoid XSS attacks. \n",
      "With bootle you can disable escaping for expressions like this: \n",
      "{{! summernotecontent}}\n",
      "\n",
      "in your case that would be:\n",
      " $('#summernote').summernote(\"code\", \"{{! content}}\");\n",
      "\n",
      "You can find the documentation on this topic in bottle here\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "I am running a remote Python script on AWS (EC2 ubuntu) in background. The script performs some file manipulations, launches a long running simulation (subprocess run with os.system(...)) and writes some log files. I would like to manage the status of the running script and hopefully exit gracefully from various conditions. Specifically:\n",
      "\n",
      "The sub-process is interrupted by the user with signal 15.\n",
      "The simulation (sub-process) fails (signal 8 - Floating point exception)\n",
      "The vm is rebooted\n",
      "The vm is terminated. I am using Elastic File System, so even if the instance is destroyed, all the files are not.\n",
      "\n",
      "I know how to handle basic exceptions, but I am a bit lost when I need to catch exceptions from subprocesses. Can you recommend a solid approach?\n",
      "EDIT: Please notice the bold part.\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!  For your given scenarios, try with signal handling. In given cases, case 1 (signal 15) and case 3 (vm is getting rebooted), are similar(generally signal 15/SIGTERM is part of shutdown sequence or maybe triggered by user with proper privileges. Nonetheless it serves the required purpose).\n",
      "signal 8 - SIGFPE\n",
      "import signal\n",
      "\n",
      "def signalHandler(sigNum, frameObject):\n",
      "    if sigNum == 15:\n",
      "       # Code for handling signal 15 goes here\n",
      "    elif sigNum == 8:\n",
      "       # Code for handling signal 8 goes here\n",
      "\n",
      "signal.signal(signal.SIGTERM, signalHandler) # signal 15\n",
      "signal.signal(signal.SIGFPE, signalHandler)  # signal 8\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "I have the following class which I intend to use in labelling specific parts of a time series.\n",
      "class Labeler(object):\n",
      "    def __init__(self, accel_data, vline=0):\n",
      "        self.fig = plt.figure(figsize=(10,2))\n",
      "\n",
      "        self.accel_data = accel_data\n",
      "        x_ = np.arange(len(self.accel_data))\n",
      "\n",
      "        self.plot, = plt.plot(x_, self.accel_data, picker=100)\n",
      "        plt.xlim(0, len(self.accel_data)-1)\n",
      "\n",
      "        self.final_loc = 0\n",
      "        self.vline_loc = 0\n",
      "        self.vline = plt.axvline(self.vline_loc, color='red')\n",
      "\n",
      "        self.fig.canvas.mpl_connect('button_press_event', self._onclick)\n",
      "\n",
      "        self.button_next = Button(plt.axes([0.85, 0.78, 0.05, 0.1]), 'Next', color='#32CD32')\n",
      "        self.button_next.on_clicked(self._nextbutton)\n",
      "\n",
      "        self.button_done = Button(plt.axes([0.85, 0.65, 0.05, 0.1]), 'Done', color='orange')\n",
      "        self.button_done.on_clicked(self._donebutton)\n",
      "        plt.show(block=True)\n",
      "\n",
      "        self.starts = []\n",
      "\n",
      "    def _onclick(self, event):\n",
      "        self.final_loc = self.vline_loc\n",
      "        self.vline_loc = int(event.xdata)\n",
      "        self.vline.set_xdata(self.vline_loc)\n",
      "\n",
      "    def _nextbutton(self, event):\n",
      "        self.starts.append(['code', self.final_loc])\n",
      "        n = np.random.randint(1000)\n",
      "        self.plot.set_xdata(np.arange(n))\n",
      "        self.plot.set_ydata(np.random.rand(n))\n",
      "        self.plot.set_title(str(n))\n",
      "\n",
      "   def _donebutton(self, event):\n",
      "        plt.close() # close to stop plot\n",
      "\n",
      "Now, I want to use this in an ipython notebook so that I can use it in a loop like this:\n",
      "for i in range(5):\n",
      "    l = Labeler(np.random.rand(1000))\n",
      "    print(l.starts) # print the locs of vertical lines\n",
      "    cont = input(\"Press any key to continue\")\n",
      "\n",
      "My problem is that when I loop over the plot, it waits until the loop is finished before displaying the plot. What I want it to do is open a single plot, determine parts using the red line, and then proceed to the next plot. Please let me know how this can be accomplished. Thanks!\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!  Solution for jupyter notebook\n",
      "The problem in a notebook is that the interactive figure prevents further code from being executed. The only solution I can think of is to let the figure take over control over the updates.\n",
      "The following would be an example (I'm sure it's not what you actually wanted, but I had problems understanding the purpose of some of the code, so it does something similar). The idea would be to provide all the data already to the class, which can then loop through it.\n",
      "%matplotlib notebook\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.widgets import Button\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class Labeler(object):\n",
      "    def __init__(self, data, vline=0):\n",
      "        self.fig = plt.figure(figsize=(10,2))\n",
      "        self.ax = self.fig.gca()\n",
      "        self.i = 0\n",
      "        self.data = data \n",
      "        \n",
      "        self.fig.canvas.mpl_connect('button_press_event', self._onclick)\n",
      "        self.button_next = Button(plt.axes([0.85, 0.78, 0.05, 0.1]), 'Next', color='#32CD32')\n",
      "        self.button_next.on_clicked(self._nextbutton)\n",
      "        self.button_done = Button(plt.axes([0.85, 0.65, 0.05, 0.1]), 'Done', color='orange')\n",
      "        self.button_done.on_clicked(self._donebutton)\n",
      "\n",
      "        self.starts = []\n",
      "        plt.show()\n",
      "        \n",
      "\n",
      "    def _nextbutton(self, event):\n",
      "        self.i\n",
      "        self.final_loc = 0\n",
      "        self.vline_loc = 0\n",
      "        self.accel_data = self.data[self.i % len(data)]\n",
      "        self.x = np.arange(len(self.accel_data))\n",
      "        plt.xlim(0, len(self.accel_data)-1)\n",
      "        self.plot, = self.ax.plot(self.x, self.accel_data, picker=100)\n",
      "        self.vline = self.ax.axvline(self.vline_loc, color='red')\n",
      "        self.starts.append(['code', self.final_loc])\n",
      "        self.ax.set_title(str(self.i))\n",
      "        self.i += 1\n",
      "        self.fig.canvas.draw()\n",
      "        \n",
      "\n",
      "    def _onclick(self, event):\n",
      "        self.final_loc = self.vline_loc\n",
      "        self.vline_loc = int(event.xdata)\n",
      "        self.vline.set_xdata(self.vline_loc)\n",
      "        self.fig.canvas.draw()\n",
      "\n",
      "\n",
      "    def _donebutton(self, event):\n",
      "        #plt.close() # close to stop plot\n",
      "        self.ax.clear()\n",
      "        pass\n",
      "\n",
      "data = []\n",
      "for i in range(5):\n",
      "    data.append(np.random.rand(60+10*i))\n",
      "l = Labeler(data)\n",
      "\n",
      "\n",
      "Solution for a console:\n",
      "The following code runs fine for me.\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.widgets import Button\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class Labeler(object):\n",
      "    def __init__(self, accel_data, vline=0):\n",
      "        self.fig = plt.figure(figsize=(10,2))\n",
      "        self.ax = self.fig.gca()\n",
      "        self.accel_data = accel_data\n",
      "        x_ = np.arange(len(self.accel_data))\n",
      "\n",
      "        self.plot, = plt.plot(x_, self.accel_data, picker=100)\n",
      "        plt.xlim(0, len(self.accel_data)-1)\n",
      "\n",
      "        self.final_loc = 0\n",
      "        self.vline_loc = 0\n",
      "        self.vline = plt.axvline(self.vline_loc, color='red')\n",
      "\n",
      "        self.fig.canvas.mpl_connect('button_press_event', self._onclick)\n",
      "\n",
      "        self.button_next = Button(plt.axes([0.85, 0.78, 0.05, 0.1]), 'Next', color='#32CD32')\n",
      "        self.button_next.on_clicked(self._nextbutton)\n",
      "\n",
      "        self.button_done = Button(plt.axes([0.85, 0.65, 0.05, 0.1]), 'Done', color='orange')\n",
      "        self.button_done.on_clicked(self._donebutton)\n",
      "        \n",
      "        self.starts = []\n",
      "        plt.show(block=True)\n",
      "\n",
      "        \n",
      "\n",
      "    def _onclick(self, event):\n",
      "        self.final_loc = self.vline_loc\n",
      "        self.vline_loc = int(event.xdata)\n",
      "        self.vline.set_xdata(self.vline_loc)\n",
      "\n",
      "    def _nextbutton(self, event):\n",
      "        self.starts.append(['code', self.final_loc])\n",
      "        n = np.random.randint(1000)\n",
      "        self.plot.set_xdata(np.arange(n))\n",
      "        self.plot.set_ydata(np.random.rand(n))\n",
      "        self.ax .set_title(str(n))\n",
      "\n",
      "    def _donebutton(self, event):\n",
      "        plt.close() # close to stop plot\n",
      "        \n",
      "for i in range(5):\n",
      "    l = Labeler(np.random.rand(1000))\n",
      "    print(l.starts) # print the locs of vertical lines\n",
      "    cont = raw_input(\"Press any key to continue\")\n",
      "\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "import json\n",
      "\n",
      "h = '{1\":{\"Name\":\"Teddies\",\"Amount\":6,\"PPU\":int(6),\"CPU\":int(4)},2:{\"Name\":\"WoodenToys\",\"Amount\":0,\"PPU\":int(15) * int(1),\"CPU\":int(10)}}'\n",
      "\n",
      "d = json.loads(h)\n",
      "\n",
      "print(d[1][\"Name\"])\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!  It looks like you have a typo at the beginning of your dict definition. \n",
      "The correct syntax should be: h = '{\"1\":{\"Name\":\"Teddies\",\"Amount\":6,\"PPU\":int(6),\"CPU\":int(4)},2:{\"Name\":\"WoodenToys\",\"Amount\":0,\"PPU\":int(15) * int(1),\"CPU\": int(10)}}'\n",
      "You can use the eval() function for this, but beware cause it's not safe and hence not recommended. \n",
      "Check out the literal_eval() function from the ast module instead. \n",
      "You will have to lose the int() parsing or do it somehow before...\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "print(data['question'][597328], '!!!!!!!!!!!!!!!!!!!!!!!!!!!', data['answers'][597328], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "print(data['question'][597329], '!!!!!!!!!!!!!!!!!!!!!!!!!!! ', data['answers'][597329], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "print(data['question'][597330], '!!!!!!!!!!!!!!!!!!!!!!!!!!! ', data['answers'][597330], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "print(data['question'][597331], '!!!!!!!!!!!!!!!!!!!!!!!!!!! ', data['answers'][597331], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "print(data['question'][597332], '!!!!!!!!!!!!!!!!!!!!!!!!!!! ', data['answers'][597332], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "print(data['question'][597333], '!!!!!!!!!!!!!!!!!!!!!!!!!!! ', data['answers'][597333], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "print(data['question'][597334], '!!!!!!!!!!!!!!!!!!!!!!!!!!! ', data['answers'][597334], '!!!!!!!!!!!!!!!!!!!!!!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4e1ae-5831-4759-8bee-6c5d73dc5df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
